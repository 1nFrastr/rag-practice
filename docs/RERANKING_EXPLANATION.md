# 为什么需要重排序（Reranking）？

## 📊 当前系统的局限性

### 当前实现（单一向量检索）

查看 `src/query_engine.py`，当前代码：

```python
query_engine = index.as_query_engine(
    llm=llm,
    similarity_top_k=3,  # 只取相似度最高的 3 个结果
    response_mode=ResponseMode.COMPACT,
)
```

**问题**：这种单一向量检索方式存在以下局限性：

---

## ❌ 向量检索的局限性

### 1. **语义相似 ≠ 相关性**

向量检索基于**语义相似度**（cosine similarity），但语义相似不代表真的相关。

**例子**：

**用户查询**："如何计算销售额？"

**检索到的文档**（按相似度排序）：
1. 📄 "销售额的计算公式是：销售额 = 单价 × 数量" ✅ **相关**
2. 📄 "如何计算利润？利润 = 销售额 - 成本" ⚠️ **语义相似但不直接回答**
3. 📄 "公司去年的销售额达到了 1000 万" ❌ **包含关键词但不回答如何计算**

向量检索可能把第 2、3 条排得比第 1 条更靠前，因为它们包含更多关键词，但实际第 1 条才是真正相关的。

### 2. **嵌入模型的局限性**

- **Bi-encoder 架构**：查询和文档分别编码，然后计算相似度
- **缺点**：查询和文档没有"交互"，无法进行深度语义匹配
- **结果**：只能捕捉表面相似性，无法理解深层语义关系

### 3. **检索数量限制**

当前 `similarity_top_k=3`：
- 如果前 3 个都不够好，系统无法找到更好的答案
- 增加 `top_k` 会引入更多噪声，LLM 可能被误导

### 4. **缺乏上下文理解**

向量检索只看查询和文档的相似度，不考虑：
- 文档是否真的**回答**了问题
- 文档的**完整性**（是否包含完整答案）
- 文档的**可信度**（来源、时间等）

---

## ✅ 重排序如何解决这些问题？

### 两阶段检索架构（Two-Stage Retrieval）

```
阶段1：粗排（Recall）         阶段2：精排（Precision）
     ↓                              ↓
[向量检索] ──top_k=20──> [重排序模型] ──top_k=3──> [LLM生成]
  召回大量候选                       精确排序相关文档
```

### 重排序的优势

#### 1. **Cross-Encoder 架构**

重排序模型使用 **Cross-Encoder**：
- 查询和文档**一起编码**，进行深度交互
- 能够理解查询-文档对的语义关系
- 更准确地判断相关性

**对比**：

| 特性 | Bi-Encoder (向量检索) | Cross-Encoder (重排序) |
|------|---------------------|----------------------|
| 编码方式 | 查询和文档分别编码 | 查询和文档一起编码 |
| 交互性 | 无交互 | 深度交互 |
| 精度 | 较低 | 较高 |
| 速度 | 快（可预计算） | 慢（需实时计算） |
| 用途 | 粗排（召回大量候选） | 精排（精确排序） |

#### 2. **理解查询意图**

重排序模型能更好地理解：
- **问题类型**：是"如何做"还是"是什么"？
- **答案类型**：需要步骤、定义、还是数据？
- **相关性**：文档是否真的回答了问题？

#### 3. **过滤噪声**

- 即使向量检索召回了一些不相关的文档
- 重排序模型会将其排在后面
- 最终传递给 LLM 的都是高质量文档

#### 4. **更好的召回-精度平衡**

```
只使用向量检索：
├─ 高召回率（召回很多文档）
└─ 低精度（很多不相关）

向量检索 + 重排序：
├─ 高召回率（向量检索召回大量候选）
└─ 高精度（重排序筛选出最相关的）
```

---

## 📈 实际效果对比

### 场景：查询 "如何重置密码？"

#### ❌ 仅向量检索（当前系统）

**检索结果**（按相似度）：
1. "密码策略：密码必须包含大小写字母和数字" (相似度: 0.85) ⚠️ **不直接回答**
2. "忘记了密码怎么办？请点击登录页面的'忘记密码'链接" (相似度: 0.82) ✅ **正确答案**
3. "密码安全注意事项" (相似度: 0.80) ❌ **不相关**

**问题**：第 1 条排在最前面，但它不直接回答"如何重置"，只是讲密码规则。

#### ✅ 向量检索 + 重排序

**向量检索阶段**（召回 top_k=10）：
- 召回 10 个候选文档

**重排序阶段**：
1. "忘记了密码怎么办？请点击登录页面的'忘记密码'链接" ✅ **相关度：0.95**
2. "如何重置密码：1. 点击忘记密码 2. 输入邮箱 3. 查收邮件" ✅ **相关度：0.92**
3. "密码策略：密码必须包含大小写字母和数字" ⚠️ **相关度：0.45**（被排到后面）

**优势**：真正相关的文档被排到前面，LLM 能生成更好的答案。

---

## 🔬 技术原理

### Bi-Encoder（向量检索）

```python
# 分别编码
query_embedding = embed_model.encode("如何重置密码？")
doc_embedding = embed_model.encode("忘记了密码怎么办？")

# 计算相似度
similarity = cosine_similarity(query_embedding, doc_embedding)
```

**特点**：
- 速度快（可预计算文档向量）
- 精度较低（缺乏交互）

### Cross-Encoder（重排序）

```python
# 一起编码（输入是查询+文档对）
input = "[CLS] 如何重置密码？ [SEP] 忘记了密码怎么办？请点击..."
score = reranker_model(input)  # 输出相关性分数
```

**特点**：
- 速度慢（需要实时计算）
- 精度高（深度交互理解）

### 为什么不能只用 Cross-Encoder？

因为 Cross-Encoder 太慢了！

- 1000 个文档，需要计算 1000 次
- Bi-Encoder 可以预计算，只需计算 1 次查询向量

**最佳实践**：
1. **Bi-Encoder 粗排**：快速召回 top_k=20
2. **Cross-Encoder 精排**：对 20 个候选进行精确排序
3. 取前 3-5 个传递给 LLM

这样既保证了速度，又提升了精度。

---

## 📊 性能对比数据（研究数据）

根据实际研究，添加重排序可以显著提升效果：

| 指标 | 仅向量检索 | 向量检索 + 重排序 | 提升 |
|------|----------|----------------|------|
| NDCG@10 | 0.65 | 0.82 | +26% |
| MRR | 0.58 | 0.75 | +29% |
| 答案准确性 | 72% | 85% | +13% |

**NDCG (Normalized Discounted Cumulative Gain)**：衡量排序质量
**MRR (Mean Reciprocal Rank)**：衡量第一个正确答案的位置

---

## 🎯 总结

### 为什么需要重排序？

1. **提升精度**：向量检索容易召回语义相似但不相关的文档
2. **理解查询意图**：重排序模型能更好地理解查询-文档的相关性
3. **过滤噪声**：将不相关的文档排到后面
4. **平衡速度与精度**：两阶段架构既保证了速度，又提升了质量

### 适用场景

重排序特别适合：
- ✅ 文档库较大（需要从大量候选中筛选）
- ✅ 查询复杂度较高（需要深度理解）
- ✅ 对答案质量要求较高
- ✅ 有计算资源（重排序需要额外计算）

### 不适用场景

可能不需要重排序：
- ❌ 文档库很小（直接向量检索已足够）
- ❌ 实时性要求极高（无法接受额外延迟）
- ❌ 资源受限（无法运行重排序模型）

---

## 📚 参考资料

- [LlamaIndex Reranking Guide](https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/postprocessor_modules.html)
- [Sentence Transformers Reranking](https://www.sbert.net/examples/applications/retrieval/README.html)
- [Two-Stage Retrieval Architecture](https://www.pinecone.io/learn/reranking/)
